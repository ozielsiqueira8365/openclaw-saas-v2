const NVIDIA_BASE_URL = process.env.NVIDIA_BASE_URL || 'https://integrate.api.nvidia.com/v1';
const NVIDIA_API_KEY = process.env.NVIDIA_API_KEY;
const MODEL = process.env.NVIDIA_MODEL || 'moonshotai/kimi-k2.5';

const LLM_TIMEOUT = 45000; // 45s
const HARD_TIMEOUT = 50000; // 50s

export async function chatHandler(req, res) {
  const { message } = req.body;
  
  if (!message) {
    return res.status(400).json({ error: 'MISSING_MESSAGE', message: 'Campo "message" é obrigatório' });
  }

  const controller = new AbortController();
  const timeoutId = setTimeout(() => controller.abort(), LLM_TIMEOUT);

  try {
    const fetchPromise = fetch(`${NVIDIA_BASE_URL}/chat/completions`, {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${NVIDIA_API_KEY}`,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({
        model: MODEL,
        messages: [{ role: 'user', content: message }],
        temperature: 0.7,
        max_tokens: 1024
      }),
      signal: controller.signal
    });

    const response = await Promise.race([
      fetchPromise,
      new Promise((_, reject) => 
        setTimeout(() => reject(new Error('HARD_TIMEOUT')), HARD_TIMEOUT)
      )
    ]);

    clearTimeout(timeoutId);

    if (!response.ok) {
      const errorText = await response.text();
      console.error('[LLM HTTP ERROR]', response.status, errorText);
      return res.status(502).json({ 
        error: 'LLM_HTTP_ERROR', 
        status: response.status,
        details: errorText.substring(0, 200)
      });
    }

    const data = await response.json();
    
    // Fallback para diferentes formatos de resposta
    const choice = data.choices?.[0];
    const content = choice?.message?.content 
      || choice?.message?.reasoning_content 
      || choice?.message?.reasoning
      || 'Sem resposta';

    // Log de uso (async, não bloqueia)
    logUsage(req.workspace.id, req.apiKeyData.id, message, content).catch(console.error);

    res.json({ 
      reply: content,
      model: MODEL,
      workspace: req.workspace.name
    });

  } catch (err) {
    clearTimeout(timeoutId);
    
    if (err.name === 'AbortError' || err.message === 'HARD_TIMEOUT') {
      return res.status(504).json({ error: 'LLM_TIMEOUT', message: 'LLM demorou muito para responder' });
    }
    
    console.error('[LLM ERROR]', err);
    res.status(502).json({ error: 'LLM_ERROR', message: err.message });
  }
}

async function logUsage(workspaceId, apiKeyId, prompt, response) {
  try {
    const { pool } = await import('../db/pool.js');
    await pool.query(
      `INSERT INTO messages (workspace_id, api_key_id, prompt, response, created_at) 
       VALUES ($1, $2, $3, $4, NOW())`,
      [workspaceId, apiKeyId, prompt.substring(0, 1000), response.substring(0, 2000)]
    );
  } catch (e) {
    console.error('[USAGE LOG ERROR]', e);
  }
}